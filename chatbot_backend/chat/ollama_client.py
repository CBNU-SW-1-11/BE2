import asyncio
import concurrent.futures
import re
import os
import requests
import json
import logging
import base64
from io import BytesIO
from PIL import Image, ImageFilter, ImageEnhance
import pytesseract

logger = logging.getLogger(__name__)

class OllamaClient:
    def __init__(self, base_url=None):
        # ê¸°ë³¸ ì£¼ì†Œ ì„¤ì •
        if base_url is None:
            # ë¨¼ì € í™˜ê²½ ë³€ìˆ˜ í™•ì¸
            base_url = os.environ.get('OLLAMA_API_URL', 'http://localhost:11434')
        self.base_url = base_url
        self.is_server_available = False
        
        # ì„œë²„ ì—°ê²° í…ŒìŠ¤íŠ¸
        try:
            response = requests.get(f"{self.base_url}/api/tags", timeout=5)
            if response.status_code == 200:
                self.is_server_available = True
                logger.info(f"Ollama ì„œë²„ ì—°ê²° ì„±ê³µ: {self.base_url}")
                # ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ í™•ì¸
                models_data = response.json()
                available_models = models_data.get('models', [])
                if available_models:
                    model_names = [model.get('name') for model in available_models]
                    logger.info(f"ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸: {', '.join(model_names)}")
                    self.available_models = model_names
                else:
                    logger.warning("ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.")
                    self.available_models = []
            else:
                logger.error(f"Ollama ì„œë²„ ì—°ê²° ì‹¤íŒ¨: {response.status_code}")
        except Exception as e:
            logger.error(f"Ollama ì„œë²„ ì—°ê²° ì‹œë„ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            self.available_models = []
    
    def preprocess_image_for_ocr(self, image):
        """OCR ì¸ì‹ë¥  í–¥ìƒì„ ìœ„í•œ ì´ë¯¸ì§€ ì „ì²˜ë¦¬"""
        # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜
        if image.mode != 'L':
            image = image.convert('L')
        
        # ë…¸ì´ì¦ˆ ì œê±° (ê°€ìš°ì‹œì•ˆ ë¸”ëŸ¬)
        image = image.filter(ImageFilter.GaussianBlur(radius=1))
        
        # ëŒ€ë¹„ í–¥ìƒ
        enhancer = ImageEnhance.Contrast(image)
        image = enhancer.enhance(2.0)  # ëŒ€ë¹„ 2ë°° ì¦ê°€
        
        # ì´ë¯¸ì§€ í¬ê¸° ì¡°ì • (í•´ìƒë„ ì¦ê°€)
        width, height = image.size
        image = image.resize((width*2, height*2), Image.BICUBIC)
        
        return image
    
    def get_optimized_ocr_text(self, image, lang='kor+eng'):
        """ìµœì í™”ëœ OCR ì„¤ì •ìœ¼ë¡œ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
        # í•œêµ­ì–´ ì¸ì‹ì— ìµœì í™”ëœ Tesseract ì„¤ì •
        custom_config = r'--oem 1 --psm 6 -c preserve_interword_spaces=1 -c textord_min_linesize=3'
        
        # OCR ì‹¤í–‰
        text = pytesseract.image_to_string(image, lang=lang, config=custom_config)
        
        # ë¶ˆí•„ìš”í•œ ê³µë°± ì •ë¦¬
        text = ' '.join(text.split())
        
        return text
    
    def _get_best_image_model(self):
        """ì‚¬ìš© ê°€ëŠ¥í•œ ìµœì ì˜ ì´ë¯¸ì§€ ëª¨ë¸ ì„ íƒ"""
        # ìš°ì„ ìˆœìœ„ì— ë”°ë¼ ì´ë¯¸ì§€ ëª¨ë¸ ì„ íƒ
        image_models = [
            "llava",             # ê¸°ë³¸ ëª¨ë¸
            "llama3-vision",     # Llama 3 ë¹„ì „ ëª¨ë¸
            "llava:13b",         # ë” í° ëª¨ë¸
            "bakllava",          # ëŒ€ì²´ ëª¨ë¸
        ]
        
        # ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ì¤‘ ìš°ì„ ìˆœìœ„ê°€ ë†’ì€ ê²ƒ ì„ íƒ
        for model in image_models:
            if model in self.available_models:
                return model
        
        # ì´ë¦„ì— "vision" ë˜ëŠ” "llava"ê°€ í¬í•¨ëœ ëª¨ë¸ ì°¾ê¸°
        for model in self.available_models:
            if "vision" in model.lower() or "llava" in model.lower():
                return model
        
        # ê¸°ë³¸ê°’ ë°˜í™˜
        return "llava"
    
    def _get_best_text_model(self):
        """ì‚¬ìš© ê°€ëŠ¥í•œ ìµœì ì˜ í…ìŠ¤íŠ¸ ëª¨ë¸ ì„ íƒ"""
        # ìš°ì„ ìˆœìœ„ì— ë”°ë¼ í…ìŠ¤íŠ¸ ëª¨ë¸ ì„ íƒ
        text_models = [
            "llama3",    # ìµœì‹  Llama 3 ëª¨ë¸
            "phi3",      # MSì˜ Phi-3 ëª¨ë¸  
            "gemma",     # Googleì˜ Gemma ëª¨ë¸
            "llama2",    # Llama 2 ëª¨ë¸
            "mistral",   # Mistral ëª¨ë¸
        ]
        
        # ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ì¤‘ ìš°ì„ ìˆœìœ„ê°€ ë†’ì€ ê²ƒ ì„ íƒ
        for model in text_models:
            if model in self.available_models:
                return model
        
        # ì´ë¦„ì— "llama"ê°€ í¬í•¨ëœ ëª¨ë¸ ì°¾ê¸°
        for model in self.available_models:
            if "llama" in model.lower():
                return model
        
        # ê¸°ë³¸ê°’ ë°˜í™˜
        return "llama3"
    
    def check_text_relevance(self, image_path, ocr_text):
        """ì´ë¯¸ì§€ì—ì„œ ì¶”ì¶œëœ í…ìŠ¤íŠ¸ê°€ ì´ë¯¸ì§€ ë‚´ìš©ê³¼ ê´€ë ¨ì´ ìˆëŠ”ì§€ í™•ì¸"""
        if not self.is_server_available:
            logger.warning("Ollama ì„œë²„ê°€ ì‚¬ìš© ë¶ˆê°€ëŠ¥í•˜ì—¬ í…ìŠ¤íŠ¸ ê´€ë ¨ì„± í™•ì¸ ë¶ˆê°€")
            return False
        
        if not ocr_text or ocr_text.strip() == "":
            logger.info("í…ìŠ¤íŠ¸ê°€ ì—†ì–´ ê´€ë ¨ì„± í™•ì¸ í•„ìš” ì—†ìŒ")
            return False
        
        try:
            # ì´ë¯¸ì§€ íŒŒì¼ ë¡œë“œ ë° base64 ì¸ì½”ë”©
            with open(image_path, "rb") as image_file:
                image_data = image_file.read()
                base64_image = base64.b64encode(image_data).decode('utf-8')
            
            # í…ìŠ¤íŠ¸ ê´€ë ¨ì„± íŒë‹¨ì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸
            relevance_prompt = f"""ì´ ì´ë¯¸ì§€ì—ì„œ ì¶”ì¶œëœ í…ìŠ¤íŠ¸ê°€ ì´ë¯¸ì§€ì˜ ë‚´ìš©ê³¼ ê´€ë ¨ì´ ìˆëŠ”ì§€ íŒë‹¨í•´ì£¼ì„¸ìš”.
    ì¶”ì¶œëœ í…ìŠ¤íŠ¸: 
    {ocr_text}

    ì´ í…ìŠ¤íŠ¸ê°€ ì´ë¯¸ì§€ì™€ ì§ì ‘ ê´€ë ¨ì´ ìˆìŠµë‹ˆê¹Œ? 
    - ì´ë¯¸ì§€ ì†ì— ì‹¤ì œë¡œ ë³´ì´ëŠ” í…ìŠ¤íŠ¸ì¸ê°€ìš”?
    - ì´ë¯¸ì§€ ë‚´ìš©ì„ ì´í•´í•˜ëŠ” ë° í•„ìš”í•œ í…ìŠ¤íŠ¸ì¸ê°€ìš”?


    "ì˜ˆ" ë˜ëŠ” "ì•„ë‹ˆì˜¤"ë¡œë§Œ ëŒ€ë‹µí•´ì£¼ì„¸ìš”."""

            # ëª¨ë¸ ì„ íƒ ë° API ìš”ì²­ ë°ì´í„° ì¤€ë¹„
            model = self._get_best_image_model()
            relevance_payload = {
                "model": model,
                "prompt": relevance_prompt,
                "images": [base64_image],
                "stream": False,
                "temperature": 0.1
            }
            
            # ê´€ë ¨ì„± íŒë‹¨ API í˜¸ì¶œ
            logger.info(f"í…ìŠ¤íŠ¸ ê´€ë ¨ì„± í™•ì¸ API í˜¸ì¶œ: ëª¨ë¸ {model}")
            relevance_response = requests.post(
                f"{self.base_url}/api/generate",
                json=relevance_payload,
                timeout=60
            )
            
            # ì‘ë‹µ ì²˜ë¦¬
            if relevance_response.status_code == 200:
                relevance_data = relevance_response.json()
                relevance_answer = relevance_data.get("response", "").lower().strip()
                
                # 'ì˜ˆ' ë˜ëŠ” 'yes'ê°€ í¬í•¨ëœ ê²½ìš° ê´€ë ¨ ìˆìŒìœ¼ë¡œ íŒë‹¨
                is_relevant = 'ì˜ˆ' in relevance_answer or 'yes' in relevance_answer
                logger.info(f"í…ìŠ¤íŠ¸ ê´€ë ¨ì„± íŒë‹¨ ê²°ê³¼: {'ê´€ë ¨ ìˆìŒ' if is_relevant else 'ê´€ë ¨ ì—†ìŒ'}")
                return is_relevant
            else:
                logger.error(f"í…ìŠ¤íŠ¸ ê´€ë ¨ì„± í™•ì¸ API ì˜¤ë¥˜: {relevance_response.status_code}")
                return False
                
        except Exception as e:
            logger.error(f"í…ìŠ¤íŠ¸ ê´€ë ¨ì„± í™•ì¸ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return False
    
    def analyze_image(self, image_path, prompt=None, ocr_text=None, text_relevant=False):
        """ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•˜ëŠ” Ollama API í˜¸ì¶œ - í…ìŠ¤íŠ¸ ê´€ë ¨ì„± ì •ë³´ í™œìš©"""
        # Ollama ì„œë²„ê°€ ì‚¬ìš© ë¶ˆê°€ëŠ¥í•œ ê²½ìš° OCRë§Œ ìˆ˜í–‰
        if not self.is_server_available:
            try:
                if not ocr_text:
                    # OCR í…ìŠ¤íŠ¸ê°€ ì œê³µë˜ì§€ ì•Šì€ ê²½ìš° ì§ì ‘ ì¶”ì¶œ
                    img = Image.open(image_path)
                    preprocessed_img = self.preprocess_image_for_ocr(img)
                    ocr_text = self.get_optimized_ocr_text(preprocessed_img, lang='kor+eng')
                
                return f"""ì´ë¯¸ì§€ ë¶„ì„ ì„œë¹„ìŠ¤ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.

    OCRë¡œ ì¶”ì¶œí•œ í…ìŠ¤íŠ¸ ë‚´ìš©:
    {ocr_text if text_relevant else "[ì´ë¯¸ì§€ì™€ ê´€ë ¨ ì—†ëŠ” í…ìŠ¤íŠ¸ê°€ ì¶”ì¶œë˜ì—ˆìŠµë‹ˆë‹¤.]"}

    â€» Ollama ì„œë²„ ì—°ê²°ì„ í™•ì¸í•´ì£¼ì„¸ìš”. ({self.base_url})
    1. Ollamaê°€ ì„¤ì¹˜ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸: https://ollama.com/download
    2. ì„œë²„ ì‹¤í–‰ í™•ì¸: 'ollama serve' ëª…ë ¹ì–´ ì‹¤í–‰
    3. ëª¨ë¸ ì„¤ì¹˜ í™•ì¸: 'ollama pull llava'"""
            except Exception as e:
                logger.error(f"OCR ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}")
                return f"ì´ë¯¸ì§€ ë¶„ì„ ë° OCR ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: Ollama ì„œë²„({self.base_url})ì— ì—°ê²°í•  ìˆ˜ ì—†ìœ¼ë©°, OCR ì²˜ë¦¬ë„ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."
        
        try:
            # ì´ë¯¸ì§€ íŒŒì¼ ë¡œë“œ ë° base64 ì¸ì½”ë”©
            with open(image_path, "rb") as image_file:
                image_data = image_file.read()
                base64_image = base64.b64encode(image_data).decode('utf-8')
            
            # OCR í…ìŠ¤íŠ¸ê°€ ì œê³µë˜ì§€ ì•Šì€ ê²½ìš° ì§ì ‘ ì¶”ì¶œ
            if ocr_text is None:
                try:
                    img = Image.open(image_path)
                    preprocessed_img = self.preprocess_image_for_ocr(img)
                    ocr_text = self.get_optimized_ocr_text(preprocessed_img, lang='kor+eng')
                    logger.info(f"ì´ë¯¸ì§€ OCR ì¶”ì¶œ ê²°ê³¼ (ì¼ë¶€): {ocr_text[:100]}...")
                    
                    # í…ìŠ¤íŠ¸ ê´€ë ¨ì„± í™•ì¸ (í…ìŠ¤íŠ¸ê°€ ìˆëŠ” ê²½ìš°ë§Œ)
                    if ocr_text and ocr_text.strip():
                        text_relevant = self.check_text_relevance(image_path, ocr_text)
                except Exception as e:
                    logger.error(f"ì´ë¯¸ì§€ OCR ì¶”ì¶œ ì˜¤ë¥˜: {str(e)}")
                    ocr_text = ""
                    text_relevant = False
            
            # ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ ì„¤ì • - í…ìŠ¤íŠ¸ ê´€ë ¨ì„±ì— ë”°ë¼ ë¶„ê¸°
            if not prompt:
                if text_relevant and ocr_text and ocr_text.strip():
                    # í…ìŠ¤íŠ¸ê°€ ì´ë¯¸ì§€ì™€ ê´€ë ¨ìˆëŠ” ê²½ìš°
                     prompt = f"""ì´ë¯¸ì§€ì—ì„œ ëˆˆìœ¼ë¡œ ì§ì ‘ í™•ì¸ ê°€ëŠ¥í•œ ì‚¬ì‹¤ë§Œ ê°„ê²°í•˜ê²Œ ì„œìˆ í•˜ì„¸ìš”.

ğŸ“Œ ì‘ì„± ê·œì¹™:
- 1-2ë¬¸ì¥ìœ¼ë¡œë§Œ ì‘ì„±
- ì‚¬ëŒ/ë™ë¬¼/ì‚¬ë¬¼ ì¤‘ ì‹¤ì œ ë³´ì´ëŠ” ê²ƒë§Œ ì–¸ê¸‰
- ìƒ‰ìƒì€ í™•ì‹¤íˆ ë³´ì´ëŠ” ê²ƒë§Œ ì–¸ê¸‰
- ìœ„ì¹˜ì™€ êµ¬ë„ëŠ” ëª…í™•íˆ ë³´ì´ëŠ” ê²ƒë§Œ ì„œìˆ 

âŒ ê¸ˆì§€ ì‚¬í•­:
- ì¶”ì¸¡ í‘œí˜„ ì‚¬ìš© ê¸ˆì§€ ("~ê°™ì€", "~ì²˜ëŸ¼ ë³´ì´ëŠ”" ë“±)
- ë³´ì´ì§€ ì•ŠëŠ” ê²ƒ ì–¸ê¸‰ ê¸ˆì§€
- ê°ì •ì´ë‚˜ ë¶„ìœ„ê¸° ë¬˜ì‚¬ ê¸ˆì§€
- ë¬¸ì¥ ë°˜ë³µ ê¸ˆì§€

OCR í…ìŠ¤íŠ¸: {ocr_text}
(í…ìŠ¤íŠ¸ëŠ” ì´ë¯¸ì§€ì™€ ê´€ë ¨ì´ ìˆëŠ” ê²½ìš°ë§Œ ì°¸ê³ í•˜ì„¸ìš”)

ì˜ì–´ë¡œ ë§¤ìš° ê°„ê²°í•˜ê²Œ ì‘ë‹µí•˜ì„¸ìš”."""
                else:
                    # í…ìŠ¤íŠ¸ê°€ ì´ë¯¸ì§€ì™€ ê´€ë ¨ì—†ê±°ë‚˜ ì—†ëŠ” ê²½ìš°
                    prompt = f"""ì´ë¯¸ì§€ì—ì„œ ëˆˆìœ¼ë¡œ ì§ì ‘ í™•ì¸ ê°€ëŠ¥í•œ ì‚¬ì‹¤ë§Œ ê°„ê²°í•˜ê²Œ ì„œìˆ í•˜ì„¸ìš”.

ğŸ“Œ ì‘ì„± ê·œì¹™:
- 1-2ë¬¸ì¥ìœ¼ë¡œë§Œ ì‘ì„±
- ì‚¬ëŒ/ë™ë¬¼/ì‚¬ë¬¼ ì¤‘ ì‹¤ì œ ë³´ì´ëŠ” ê²ƒë§Œ ì–¸ê¸‰
- ìƒ‰ìƒì€ í™•ì‹¤íˆ ë³´ì´ëŠ” ê²ƒë§Œ ì–¸ê¸‰ 
- ìœ„ì¹˜ì™€ êµ¬ë„ëŠ” ëª…í™•íˆ ë³´ì´ëŠ” ê²ƒë§Œ ì„œìˆ 

âŒ ê¸ˆì§€ ì‚¬í•­:
- ì¶”ì¸¡ í‘œí˜„ ì‚¬ìš© ê¸ˆì§€ ("~ê°™ì€", "~ì²˜ëŸ¼ ë³´ì´ëŠ”" ë“±)
- ë³´ì´ì§€ ì•ŠëŠ” ê²ƒ ì–¸ê¸‰ ê¸ˆì§€
- ê°ì •ì´ë‚˜ ë¶„ìœ„ê¸° ë¬˜ì‚¬ ê¸ˆì§€
- ë¬¸ì¥ ë°˜ë³µ ê¸ˆì§€

ì˜ì–´ë¡œë¡œ ë§¤ìš° ê°„ê²°í•˜ê²Œ ì‘ë‹µí•˜ì„¸ìš”."""
            
            # ëª¨ë¸ ì„ íƒ - ì‚¬ìš© ê°€ëŠ¥í•œ ê²½ìš° ë” ë‚˜ì€ ëª¨ë¸ ì„ íƒ
            model = self._get_best_image_model()
            
            # API ìš”ì²­ ë°ì´í„° ì¤€ë¹„
            payload = {
                "model": model,
                "prompt": prompt,
                "images": [base64_image],
                "stream": False,
                "temperature": 0.1  # ë‚®ì€ ì˜¨ë„ë¡œ ë” ì •í™•í•œ ì‘ë‹µ ìœ ë„
            }
            
            logger.info(f"Ollama API ìš”ì²­: /api/generate (ì´ë¯¸ì§€ ë¶„ì„) ëª¨ë¸: {model}")
            # API í˜¸ì¶œ
            response = requests.post(
                f"{self.base_url}/api/generate",
                json=payload,
                timeout=180  # íƒ€ì„ì•„ì›ƒ 3ë¶„ìœ¼ë¡œ ì—°ì¥
            )
            
            # ì‘ë‹µ ì²˜ë¦¬ ë° ë¡œê¹…
            logger.info(f"Ollama API ì‘ë‹µ ìƒíƒœ ì½”ë“œ: {response.status_code}")
            
            if response.status_code == 200:
                try:
                    response_data = response.json()
                    api_response = response_data.get("response", "ì‘ë‹µì„ ë°›ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                    logger.info(f"Ollama API ì‘ë‹µ ë‚´ìš© (ì¼ë¶€): {api_response[:100]}...")
                    
                    # ì‘ë‹µì´ OCR í…ìŠ¤íŠ¸ì™€ ë™ì¼í•œì§€ í™•ì¸ (ì˜¤ë¥˜ ê°ì§€)
                    if ocr_text and len(ocr_text) > 20 and api_response.strip().startswith(ocr_text[:20].strip()):
                        if text_relevant:
                            return f"ì´ë¯¸ì§€ ë¶„ì„: ì´ë¯¸ì§€ì—ëŠ” ì£¼ë¡œ í…ìŠ¤íŠ¸ê°€ í¬í•¨ë˜ì–´ ìˆìœ¼ë©°, í…ìŠ¤íŠ¸ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤: {ocr_text}"
                        else:
                            return "ì´ë¯¸ì§€ë¥¼ ì œëŒ€ë¡œ ë¶„ì„í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì´ë¯¸ì§€ì— í…ìŠ¤íŠ¸ê°€ í¬í•¨ë˜ì–´ ìˆì§€ë§Œ ì´ë¯¸ì§€ì˜ ì‹œê°ì  ë‚´ìš©ê³¼ ê´€ë ¨ì´ ì—†ìŠµë‹ˆë‹¤."
                    
                    return api_response
                except json.JSONDecodeError:
                    logger.error("JSON íŒŒì‹± ì˜¤ë¥˜")
                    return response.text
            elif response.status_code == 400 and "model not found" in response.text.lower():
                # ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ëŠ” ê²½ìš°
                return f"""ìš”ì²­í•œ ì´ë¯¸ì§€ ë¶„ì„ ëª¨ë¸({model})ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.

    ë‹¤ìŒ ëª…ë ¹ì–´ë¡œ ëª¨ë¸ì„ ì„¤ì¹˜í•´ì£¼ì„¸ìš”:
    'ollama pull {model}'

    ë˜ëŠ” ì´ë¯¸ì§€ ë¶„ì„ì— ìµœì í™”ëœ ìµœì‹  ëª¨ë¸ ì„¤ì¹˜:
    'ollama pull llava'

    OCRë¡œ ì¶”ì¶œí•œ í…ìŠ¤íŠ¸ ë‚´ìš©:
    {ocr_text if text_relevant else "[ì´ë¯¸ì§€ì™€ ê´€ë ¨ ì—†ëŠ” í…ìŠ¤íŠ¸ê°€ ì¶”ì¶œë˜ì—ˆìŠµë‹ˆë‹¤.]"}"""
            else:
                # 404 ì˜¤ë¥˜ ë“± íŠ¹ë³„ ì²˜ë¦¬
                if response.status_code == 404:
                    return f"""Ollama APIì— ì ‘ê·¼í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤ (404 ì˜¤ë¥˜).

    OCRë¡œ ì¶”ì¶œí•œ í…ìŠ¤íŠ¸ ë‚´ìš©:
    {ocr_text if text_relevant else "[ì´ë¯¸ì§€ì™€ ê´€ë ¨ ì—†ëŠ” í…ìŠ¤íŠ¸ê°€ ì¶”ì¶œë˜ì—ˆìŠµë‹ˆë‹¤.]"}

    â€» ë‹¤ìŒ ì‚¬í•­ì„ í™•ì¸í•´ì£¼ì„¸ìš”:
    1. Ollamaê°€ ì„¤ì¹˜ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸: https://ollama.com/download
    2. ì„œë²„ ì‹¤í–‰ í™•ì¸: 'ollama serve' ëª…ë ¹ì–´ ì‹¤í–‰
    3. ëª¨ë¸ ì„¤ì¹˜ í™•ì¸: 'ollama pull llava'"""
                    
                raise Exception(f"Ollama API ì˜¤ë¥˜: {response.status_code}")
                
        except Exception as e:
            logger.error(f"Ollama ì´ë¯¸ì§€ ë¶„ì„ ì˜¤ë¥˜: {str(e)}")
            # OCR ê²°ê³¼ëŠ” ì œê³µ
            try:
                if not ocr_text:
                    img = Image.open(image_path)
                    preprocessed_img = self.preprocess_image_for_ocr(img)
                    ocr_text = self.get_optimized_ocr_text(preprocessed_img, lang='kor+eng')
                    
                    # í…ìŠ¤íŠ¸ ê´€ë ¨ì„± í™•ì¸
                    if ocr_text and ocr_text.strip():
                        text_relevant = self.check_text_relevance(image_path, ocr_text)
                
                return f"""ì´ë¯¸ì§€ ë¶„ì„ ì„œë¹„ìŠ¤ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.

    OCRë¡œ ì¶”ì¶œí•œ í…ìŠ¤íŠ¸ ë‚´ìš©:
    {ocr_text if text_relevant else "[ì´ë¯¸ì§€ì™€ ê´€ë ¨ ì—†ëŠ” í…ìŠ¤íŠ¸ê°€ ì¶”ì¶œë˜ì—ˆìŠµë‹ˆë‹¤.]"}

    â€» ì˜¤ë¥˜: {str(e)}"""
            except:
                return f"ì´ë¯¸ì§€ ë¶„ì„ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
   
    def _get_best_text_model(self):
        """ì‚¬ìš© ê°€ëŠ¥í•œ ìµœì ì˜ í…ìŠ¤íŠ¸ ëª¨ë¸ ì„ íƒ"""
        # ìš°ì„ ìˆœìœ„ì— ë”°ë¼ í…ìŠ¤íŠ¸ ëª¨ë¸ ì„ íƒ
        text_models = [
            "llama3",    # ìµœì‹  Llama 3 ëª¨ë¸
            "phi3",      # MSì˜ Phi-3 ëª¨ë¸  
            "gemma",     # Googleì˜ Gemma ëª¨ë¸
            "llama2",    # Llama 2 ëª¨ë¸
            "mistral",   # Mistral ëª¨ë¸
        ]
        
        # ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ì¤‘ ìš°ì„ ìˆœìœ„ê°€ ë†’ì€ ê²ƒ ì„ íƒ
        for model in text_models:
            if model in self.available_models:
                return model
        
        # ì´ë¦„ì— "llama"ê°€ í¬í•¨ëœ ëª¨ë¸ ì°¾ê¸°
        for model in self.available_models:
            if "llama" in model.lower():
                return model
        
        # ê¸°ë³¸ê°’ ë°˜í™˜
        return "llama3"
            
    def _detect_page_boundaries(self, text):
        """í…ìŠ¤íŠ¸ì—ì„œ í˜ì´ì§€ ê²½ê³„ ê°ì§€ (ë‹¤ì–‘í•œ í˜•ì‹ ì§€ì›)"""
        # ì¼ë°˜ì ì¸ í˜ì´ì§€ êµ¬ë¶„ì íŒ¨í„´ë“¤
        page_patterns = [
            r'(?i)(?:^|\n)[\s-]*í˜ì´ì§€\s*(\d+)[\s-]*(?:\n|$)',    # "í˜ì´ì§€ 1" í˜•ì‹
            r'(?i)(?:^|\n)[\s-]*page\s*(\d+)[\s-]*(?:\n|$)',      # "Page 1" í˜•ì‹
            r'(?i)(?:^|\n)[\s-]*p\.?\s*(\d+)[\s-]*(?:\n|$)',      # "p. 1" í˜•ì‹
            r'(?i)(?:^|\n)[\s-]*\[(\d+)\][\s-]*(?:\n|$)',         # "[1]" í˜•ì‹
            r'(?i)(?:^|\n)[\s-]*-\s*(\d+)\s*-[\s-]*(?:\n|$)',     # "- 1 -" í˜•ì‹
        ]
        
        # ëª¨ë“  í˜ì´ì§€ êµ¬ë¶„ì ì°¾ê¸°
        pages = []
        last_pos = 0
        current_page = 1
        
        # ë¨¼ì € ëª¨ë“  íŒ¨í„´ìœ¼ë¡œ ë§¤ì¹˜ ê²€ìƒ‰
        all_matches = []
        for pattern in page_patterns:
            for match in re.finditer(pattern, text):
                try:
                    page_num = int(match.group(1))
                    all_matches.append((match.start(), page_num, match.end()))
                except:
                    pass
        
        # ë§¤ì¹˜ê°€ ì—†ìœ¼ë©´ ë¹ˆ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜
        if not all_matches:
            return []
        
        # ìœ„ì¹˜ë¡œ ì •ë ¬
        all_matches.sort()
        
        # í˜ì´ì§€ë³„ë¡œ ë¶„í• 
        for i, (pos, page_num, end_pos) in enumerate(all_matches):
            # ì²« ë²ˆì§¸ ë§¤ì¹˜ê°€ ì•„ë‹ˆë¼ë©´ ì´ì „ í˜ì´ì§€ ë‚´ìš© ì €ì¥
            if i > 0:
                content = text[last_pos:pos].strip()
                if content:
                    pages.append({"page": current_page, "text": content})
            
            current_page = page_num
            last_pos = end_pos
        
        # ë§ˆì§€ë§‰ í˜ì´ì§€ ë‚´ìš© ì¶”ê°€
        if last_pos < len(text):
            content = text[last_pos:].strip()
            if content:
                pages.append({"page": current_page, "text": content})
        
        return pages

    def analyze_text(self, text, prompt=None, page_texts=None):
            """í…ìŠ¤íŠ¸ë¥¼ ë¶„ì„í•˜ëŠ” Ollama API í˜¸ì¶œ - ì†ë„ ê°œì„  ë²„ì „"""
            try:
                # í…ìŠ¤íŠ¸ê°€ ë¹„ì–´ìˆëŠ”ì§€ í™•ì¸
                if not text or text.strip() == "":
                    return "ë¶„ì„í•  í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤."
                
                # í˜ì´ì§€ë³„ ë¶„ì„ ì—¬ë¶€ íŒë‹¨
                analyze_by_page = False
                pages = []
                
                # ì œê³µëœ í˜ì´ì§€ í…ìŠ¤íŠ¸ê°€ ìˆëŠ” ê²½ìš°
                if page_texts and isinstance(page_texts, list) and len(page_texts) > 1:
                    analyze_by_page = True
                    pages = page_texts
                else:
                    # í…ìŠ¤íŠ¸ì—ì„œ í˜ì´ì§€ ê²½ê³„ë¥¼ ìë™ ê°ì§€
                    detected_pages = self._detect_page_boundaries(text)
                    if detected_pages and len(detected_pages) > 1:
                        analyze_by_page = True
                        pages = detected_pages
                
                # ëª¨ë¸ ì„ íƒ (í•œêµ­ì–´ ì²˜ë¦¬ì— ìµœì í™”ëœ ëª¨ë¸ ì‚¬ìš©)
                model = self._get_best_text_model()
                
                if analyze_by_page and len(pages) > 3:  # 3í˜ì´ì§€ ì´ìƒì¼ ë•Œë§Œ ìµœì í™”
                    # ë°©ë²• 1: ì „ì²´ í…ìŠ¤íŠ¸ë¥¼ í•œ ë²ˆì— ì²˜ë¦¬í•˜ê³  í˜ì´ì§€ë³„ êµ¬ë¶„ ìš”ì²­ (ë°°ì¹˜ ì²˜ë¦¬)
                    formatted_pages = ""
                    for page in pages:
                        page_num = page.get("page", 1)
                        page_text = page.get("text", "").strip()
                        if page_text:
                            formatted_pages += f"===== í˜ì´ì§€ {page_num} =====\n{page_text}\n\n"
                    
                    batch_prompt = f"""ë‹¤ìŒì€ ë¬¸ì„œì˜ ì—¬ëŸ¬ í˜ì´ì§€ ë‚´ìš©ì…ë‹ˆë‹¤. ê° í˜ì´ì§€ë¥¼ êµ¬ë¶„í•˜ì—¬ ë¶„ì„í•´ì£¼ì„¸ìš”:

        {formatted_pages}

        ê° í˜ì´ì§€ì˜ ë‚´ìš©ì„ ë‹¤ìŒ ê°€ì´ë“œë¼ì¸ì— ë”°ë¼ ì •ë¦¬í•´ì£¼ì„¸ìš”:
        ê° í˜ì´ì§€ì˜ OCR ì¶”ì¶œ ê²°ê³¼ë¥¼ ë„£ì–´ì£¼ì„¸ìš”.
   
        ë°˜ë“œì‹œ ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”:
        ===== í˜ì´ì§€ 1 ë¶„ì„ =====
        (page 1 OCR ì¶”ì¶œ ê²°ê³¼,ë¶„ì„ ë‚´ìš©)

        ===== í˜ì´ì§€ 2 ë¶„ì„ =====
        (page 2 OCR ì¶”ì¶œ ê²°ê³¼,ë¶„ì„ ë‚´ìš©)

        ...

        ë°˜ë“œì‹œ "ì˜ì–´(En)"ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”."""

                    # API ìš”ì²­ ë°ì´í„° ì¤€ë¹„ - í† í° ìˆ˜ ì¦ê°€
                    payload = {
                        "model": model,
                        "prompt": batch_prompt,
                        "stream": False,
                        "temperature": 0.3,  # ì •í™•ì„± ì¤‘ì‹œ
                        "max_tokens": 4096   # í† í° ìˆ˜ ì¦ê°€
                    }
                    
                    # API í˜¸ì¶œ
                    response = requests.post(
                        f"{self.base_url}/api/generate",
                        json=payload,
                        timeout=300  # ì‹œê°„ ì¦ê°€
                    )
                    
                    if response.status_code == 200:
                        response_data = response.json()
                        return response_data.get("response", "ì‘ë‹µì„ ë°›ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                    else:
                        raise Exception(f"Ollama API ì˜¤ë¥˜: {response.status_code}")
                        
                elif analyze_by_page:
                    # ë°©ë²• 2: ë¹„ë™ê¸° ì²˜ë¦¬ë¡œ ì—¬ëŸ¬ í˜ì´ì§€ ë™ì‹œì— ì²˜ë¦¬
                    async def process_pages():
                        # ìµœëŒ€ ë™ì‹œ ì‘ì—… ìˆ˜ ì œí•œ
                        max_workers = min(5, len(pages))  # ìµœëŒ€ 5ê°œ í˜ì´ì§€ ë™ì‹œ ì²˜ë¦¬
                        
                        async def analyze_page(page_data):
                            page_num = page_data.get("page", 1)
                            page_text = page_data.get("text", "")
                            
                            if not page_text.strip():
                                return f"===== í˜ì´ì§€ {page_num} =====\ní˜ì´ì§€ ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤.\n"
                            
                            page_prompt = f"""ë‹¤ìŒì€ ë¬¸ì„œì˜ {page_num}í˜ì´ì§€ì—ì„œ ì¶”ì¶œí•œ í…ìŠ¤íŠ¸ì…ë‹ˆë‹¤:

        {page_text}


        ì´ í˜ì´ì§€ì˜ ë‚´ìš©ì„ ìì„¸íˆ ë¶„ì„í•˜ê³  ì •ë¦¬í•´ì£¼ì„¸ìš”.
        ë‹¨ìˆœ ìš”ì•½ì´ ì•„ë‹Œ í˜ì´ì§€ì˜ í•µì‹¬ ì •ë³´ë¥¼ ì¶©ì‹¤í•˜ê²Œ ì •ë¦¬í•´ì£¼ì„¸ìš”.
        "ë¶ˆì™„ì „í•˜ë‹¤", "ë‹¨í¸ì ì´ë‹¤", "ì†Œê°œê°€ ë¶€ì¡±í•˜ë‹¤" ë“±ì˜ í‘œí˜„ ê¸ˆì§€
        ë‹¨, ë¬¸ì¥ì´ë‚˜ ë‹¨ì–´ê°€ ì•„ë‹ˆë¼ê³  ìƒê°ë  ê²½ìš° ë¶„ì„í•˜ì§€ ì•Šì•„ë„ ë©ë‹ˆë‹¤. ë˜ëŠ” ì •ë³´ ì—†ìŒì´ë¼ê³  ì¶œë ¥
        ë°˜ë“œì‹œ "ì˜ì–´(En)"ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”."""
                            
                            # ThreadPoolExecutorë¥¼ ì‚¬ìš©í•˜ì—¬ ë¹„ë™ê¸° HTTP ìš”ì²­
                            with concurrent.futures.ThreadPoolExecutor() as executor:
                                page_payload = {
                                    "model": model,
                                    "prompt": page_prompt,
                                    "stream": False,
                                    "temperature": 0.3,
                                    "max_tokens": 1024
                                }
                                
                                def make_request():
                                    try:
                                        r = requests.post(
                                            f"{self.base_url}/api/generate",
                                            json=page_payload,
                                            timeout=180
                                        )
                                        if r.status_code == 200:
                                            data = r.json()
                                            return f"===== í˜ì´ì§€ {page_num} =====\n{data.get('response', 'ë¶„ì„ ì‹¤íŒ¨')}"
                                        return f"===== í˜ì´ì§€ {page_num} =====\ní˜ì´ì§€ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {r.status_code}"
                                    except Exception as e:
                                        return f"===== í˜ì´ì§€ {page_num} =====\ní˜ì´ì§€ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
                                
                                return await asyncio.get_event_loop().run_in_executor(executor, make_request)
                        
                        # í˜ì´ì§€ ê·¸ë£¹í™” - 2í˜ì´ì§€ì”© ë¬¶ê¸°
                        grouped_pages = []
                        for i in range(0, len(pages), 2):  # 2í˜ì´ì§€ì”© ê·¸ë£¹í™”
                            group = pages[i:i+2]
                            if group:
                                grouped_text = "\n\n".join([p.get("text", "") for p in group])
                                start_page = group[0].get("page", 1)
                                end_page = group[-1].get("page", start_page)
                                grouped_pages.append({
                                    "page": f"{start_page}-{end_page}",
                                    "text": grouped_text
                                })
                        
                        # ë™ì‹œì— ì²˜ë¦¬í•  í˜ì´ì§€ ê·¸ë£¹ ë¶„ì„
                        tasks = [analyze_page(page) for page in grouped_pages]
                        results = await asyncio.gather(*tasks)
                        return "\n\n".join(results)
                    
                    # ë¹„ë™ê¸° ì‹¤í–‰ ê²°ê³¼ ë°˜í™˜
                    loop = asyncio.new_event_loop()
                    asyncio.set_event_loop(loop)
                    try:
                        return loop.run_until_complete(process_pages())
                    finally:
                        loop.close()
                else:
                    # ê¸°ì¡´ ë°©ì‹ - ë‹¨ì¼ ë¬¸ì„œ ë˜ëŠ” ì ì€ í˜ì´ì§€ ìˆ˜
                    prompt = f"""ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ ìì„¸íˆ ë¶„ì„í•˜ê³  ë‚´ìš©ì„ ëª…í™•í•˜ê²Œ ì •ë¦¬í•´ì£¼ì„¸ìš”:

        {text}

        ë¶„ì„ ì§€ì¹¨:
        1. í…ìŠ¤íŠ¸ì˜ ì£¼ìš” ë‚´ìš©ê³¼ êµ¬ì¡°ë¥¼ ëª…í™•í•˜ê²Œ íŒŒì•…í•˜ì—¬ ì •ë¦¬
        2. ë‹¨ìˆœ ìš”ì•½ì´ ì•„ë‹Œ, í…ìŠ¤íŠ¸ì˜ í•µì‹¬ ì •ë³´ë¥¼ ì¶©ì‹¤í•˜ê²Œ ì •ë¦¬
        3. ì¤‘ìš”í•œ ì„¹ì…˜ì´ë‚˜ ì£¼ì œë³„ë¡œ êµ¬ë¶„í•˜ì—¬ ì •ë¦¬
        4. ëª¨ë“  ì¤‘ìš”í•œ ì„¸ë¶€ ì •ë³´ë¥¼ í¬í•¨
        ë‹¨, ë¬¸ì¥ì´ë‚˜ ë‹¨ì–´ê°€ ì•„ë‹ˆë¼ê³  ìƒê°ë  ê²½ìš° ë¶„ì„í•˜ì§€ ì•Šì•„ë„ ë©ë‹ˆë‹¤. ë˜ëŠ” ì •ë³´ ì—†ìŒì´ë¼ê³  ì¶œë ¥
        ë°˜ë“œì‹œ "ì˜ì–´(En)"(En)ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”."""
                    
                    if prompt:
                        # ê¸°ì¡´ í”„ë¡¬í”„íŠ¸ì— í…ìŠ¤íŠ¸ ì¶”ê°€
                        if "{text}" in prompt:
                            prompt = prompt.format(text=text)
                        else:
                            prompt = f"{prompt}\n\n{text}"
                    
                    # API ìš”ì²­ ë°ì´í„° ì¤€ë¹„
                    payload = {
                        "model": model,
                        "prompt": prompt,
                        "stream": False,
                        "temperature": 0.7,
                        "top_p": 0.9,
                        "max_tokens": 2048
                    }
                    
                    # API í˜¸ì¶œ
                    response = requests.post(
                        f"{self.base_url}/api/generate",
                        json=payload,
                        timeout=180
                    )
                    
                    if response.status_code == 200:
                        response_data = response.json()
                        return response_data.get("response", "ì‘ë‹µì„ ë°›ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                    else:
                        raise Exception(f"Ollama API ì˜¤ë¥˜: {response.status_code}")
            
            except Exception as e:
                logger.error(f"Ollama í…ìŠ¤íŠ¸ ë¶„ì„ ì˜¤ë¥˜: {str(e)}")
                return f"í…ìŠ¤íŠ¸ ë¶„ì„ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

